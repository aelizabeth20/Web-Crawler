# Web-Crawler
Python 3 Web Crawler

This is a pretty simple project. It's something I created after learning some of the basics of Python. The goal is to look at the input
website and grab all of the links on that page using regular expressions. These are then written to a file but they DO NOT maintain any 
order. The program runs until it has been through every website in the output file. It keeps track of the websites it has already
seen in a seperate file to eliminate duplicates. It uses a total of 5 threads to accomplish its task.

The idea for this project came from a similiar program written by @srobison12 who wrote it in Golang.
